{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "# Parsear el contenido HTML\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Página 1: []\n",
      "Página 2: []\n",
      "Todos los números únicos encontrados:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def scrape_multiple_pages(num_iterations):\n",
    "    # Inicializar el controlador de Selenium (en este ejemplo, uso Chrome, puedes ajustarlo según tu navegador)\n",
    "    driver = webdriver.Chrome()\n",
    "    #num_iterations=num_iterations+10\n",
    "    # Lista para almacenar todos los números únicos encontrados\n",
    "    all_unique_digits = []\n",
    "\n",
    "    # Iterar sobre el número de páginas especificado\n",
    "    for page_number in range(1, num_iterations + 1):\n",
    "        # Construir la URL de la página actual\n",
    "        url = f'https://baloto.com/resultados?page={page_number}'\n",
    "        \n",
    "        # Navegar a la página\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Obtener el HTML de la página actual\n",
    "        html = driver.page_source\n",
    "        \n",
    "        # Analizar el contenido HTML con BeautifulSoup\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        \n",
    "        # Lista para almacenar los resultados de la página actual\n",
    "        digits = []\n",
    "\n",
    "        # Encontrar todas las etiquetas <td>\n",
    "        td_elements = soup.find_all('td')\n",
    "\n",
    "        for td in td_elements:\n",
    "            number = td.get_text().strip()  # Extraer el texto del <td>\n",
    "            if re.match(r'^\\d{4}$', number):  # Verificar si el texto contiene exactamente 4 dígitos\n",
    "                digits.append(number)  # Añadir el número a la lista\n",
    "\n",
    "        # Convertir la lista a un conjunto para eliminar duplicados y luego volver a convertirla en lista\n",
    "        unique_digits = list(set(digits))\n",
    "\n",
    "        # Extender la lista acumulativa con los números únicos de esta página\n",
    "        all_unique_digits.extend(unique_digits)\n",
    "        \n",
    "        # Imprimir los números únicos de la página actual\n",
    "        print(f'Página {page_number}: {unique_digits}')\n",
    "\n",
    "    # Cerrar el navegador al finalizar\n",
    "    driver.quit()\n",
    "\n",
    "    # Devolver todos los números únicos encontrados en todas las páginas\n",
    "    return all_unique_digits\n",
    "\n",
    "# Ejemplo de uso: obtener números únicos de las primeras 3 páginas\n",
    "results = scrape_multiple_pages(2)\n",
    "print(\"Todos los números únicos encontrados:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combinacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_horario = pd.DataFrame(columns=['sorteo', 'fecha_sorteo'])\n",
    "df_yellow = pd.DataFrame(columns=['sorteo', 'yellows'])\n",
    "df_red = pd.DataFrame(columns=['sorteo', 'reds'])\n",
    "\n",
    "for result in results:\n",
    "    url = f'https://baloto.com/resultados-baloto/{result}'\n",
    "    driver = webdriver.Chrome()\n",
    "    # Navegar a la página\n",
    "    driver.get(url)\n",
    "    # Esperar hasta que el elemento de interés esté presente en el DOM (por ejemplo, el primer elemento con la clase 'yellow-ball')\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'yellow-ball')))\n",
    "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, 'red-ball')))\n",
    "    # Obtener el HTML de la página actual\n",
    "    html = driver.page_source\n",
    "  \n",
    "    # Analizar el contenido HTML con BeautifulSoup\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    fecha_element = soup.find('div', class_='gotham-medium dark-blue')\n",
    "    fecha_element = fecha_element.get_text().strip()\n",
    "    \n",
    "    df_temp = pd.DataFrame({'sorteo': [result],'fecha_sorteo':[fecha_element]})\n",
    "    df_horario = pd.concat([df_horario, df_temp], ignore_index=True)\n",
    "    \n",
    "    numbers1 = []\n",
    "    elements1 = soup.find_all(class_='yellow-ball')\n",
    "\n",
    "    for element1 in elements1:\n",
    "        number1 = element1.get_text().strip()  # Obtener el texto y eliminar espacios en blanco\n",
    "        numbers1.append(int(number1))  # Convertir el texto a entero y añadir a la lista\n",
    "\n",
    "\n",
    "    df_temp1 = pd.DataFrame({'sorteo': [result],'yellows': [numbers1]})\n",
    "    df_yellow = pd.concat([df_yellow, df_temp1], ignore_index=True)\n",
    "    \n",
    "    reds = []\n",
    "    elements_red = soup.find_all(class_='red-ball')\n",
    "\n",
    "    for element_red in elements_red:\n",
    "        red = element_red.get_text().strip()  # Obtener el texto y eliminar espacios en blanco\n",
    "        reds.append(int(red))  # Convertir el texto a entero y añadir a la lista\n",
    "\n",
    "    df_temp2 = pd.DataFrame({'sorteo': [result],'reds': [red]})\n",
    "    df_red = pd.concat([df_red, df_temp2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = df_horario.merge(df_yellow, on='sorteo').merge(df_red, on='sorteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sorteo</th>\n",
       "      <th>fecha_sorteo</th>\n",
       "      <th>yellows</th>\n",
       "      <th>reds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [sorteo, fecha_sorteo, yellows, reds]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_filename = './outs/resultados_baloto2.xlsx'\n",
    "df_combined.to_excel(excel_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataing2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
